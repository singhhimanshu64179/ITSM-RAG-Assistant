ğŸ“˜ ITSM RAG Assistant â€“ AI-Powered ITIL Knowledge Assistant

A Retrieval-Augmented Generation (RAG) application designed for IT Service Management (ITSM) teams.
This assistant uses local LLMs (Llama 3, Phi-3 via Ollama) + LangChain 0.3+ + ChromaDB to answer ITIL/SOP-based questions such as:

Incident Management
Major Incident workflow
Problem Management & RCA
Change Management (Normal, Standard, Emergency)
CMDB & CI Relationships
SLA Matrix / Priority Matrix
On-call Procedures
ITIL v3/v4 Practices

Powered by your own SOP documents, ensuring 0% cloud dependency, 100% privacy, and highly accurate responses.

ğŸš€ Features
Feature	Description
ğŸ” RAG Search	Retrieves most relevant SOP sections using ChromaDB
ğŸ§  Local LLM	Uses Llama3 / Phi-3 via Ollama (no API cost, fully offline)
ğŸ“„ Source Tracing	Shows exactly which documents were used
ğŸ’¬ Chat Bubble UI	ChatGPT-style modern chat interface
ğŸ“ Chat History	Stores all questions & responses
ğŸ—‘ï¸ Clear Chat	Reset conversation at any time
ğŸŒ™ Dark Mode Toggle	Light / dark theme switch
ğŸ—£ï¸ Voice Input	Ask questions by speaking
ğŸ“„ Export Answer as PDF	Download generated responses
ğŸ“¦ Export Chat as TXT / JSON	Save your entire conversation
ğŸ”€ Multi-Model Selector	Switch between Llama3, Phi-3, Mistral (Ollama)
ğŸ¯ ITSM Focused	Trained on SOPs for Incident, Change, Problem, CMDB, SLA etc.
ğŸ§  How It Works (Architecture)
flowchart TD
    A[User Query] --> B[Retriever (ChromaDB)]
    B --> C[Relevant SOP Chunks]
    C --> D[Prompt Template]
    D --> E[Local LLM via Ollama]
    E --> F[Final Answer]
    F --> G[Streamlit UI]

    B <---> H[HuggingFace Embeddings]

ğŸ“‚ Project Structure
ITSM_RAG_ASSISTANCE/
â”‚â”€â”€ app.py                     # Streamlit UI with chat, PDF, voice, dark mode
â”‚â”€â”€ ingest.py                  # Loads SOP files â†’ creates vector DB
â”‚â”€â”€ data/                      # Your ITIL & ITSM SOP documents
â”‚   â””â”€â”€ sops/                  # All .txt knowledge files
â”‚â”€â”€ vectordb/                  # ChromaDB auto-generated embeddings
â”‚â”€â”€ requirements.txt           # Python dependencies
â”‚â”€â”€ .gitignore                 # Prevents uploading venv & vectordb
â”‚â”€â”€ README.md                  # (This file)
â””â”€â”€ venv/                      # Virtual environment (ignored)

ğŸ›  Technologies Used

Python 3.10+
LangChain 0.3+ (Runnables API)
ChromaDB
SentenceTransformers (MiniLM-L6-v2)
Ollama (Llama3, Phi-3, Mistral)
Streamlit
ReportLab (PDF generation)
SpeechRecognition (Voice input)

ğŸ“¥ Local Setup Instructions
1ï¸âƒ£ Clone repository
git clone https://github.com/<your-username>/ITSM-RAG-Assistant
cd ITSM-RAG-Assistant

2ï¸âƒ£ Create virtual environment
python -m venv venv
venv\Scripts\activate

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Install Ollama

Download from: https://ollama.com/download

5ï¸âƒ£ Pull LLM model(s)
ollama pull llama3


Optional faster models:

ollama pull phi3
ollama pull llama3:instruct

6ï¸âƒ£ Build the vector database
python ingest.py

7ï¸âƒ£ Run the app
streamlit run app.py


Your assistant is now live at:

ğŸ‘‰ http://localhost:8501

ğŸ§ª Example Questions

Try asking:

â€œWhat is the Incident Management lifecycle?â€
â€œExplain Major Incident communication workflow.â€
â€œWhat is the Impact-Urgency Priority Matrix?â€
â€œShow me CMDB structure and CI attributes.â€
â€œWhat is the difference between Standard and Emergency Change?â€
â€œGive me RCA steps for recurring incidents.â€

ğŸ“¸ Screenshots (Add after uploading)
![ITSM RAG UI](ui.png)
![Dark Mode](darkmode.png)
![Sources Example](Source.png)

ğŸ§© Future Enhancements
ğŸ”¥ Support for multimodal ITSM data (PDFs, DOCX)
ğŸ—‚ï¸ Dashboard for analytics & incident trends
ğŸ¤– Add memory-based reasoning for repeated conversations
ğŸŒ Deploy on cloud VM or Docker container
ğŸ“ Multi-language ITIL support
ğŸ§µ Add full conversation context window
ğŸ™Œ Contributions

Contributions, ideas, and improvements are welcome.
Feel free to open issues or PRs!
